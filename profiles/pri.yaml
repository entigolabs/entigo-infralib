#This profile is for starting up a simple EKS cluster for private use.
#The net setup is only over 1 AZ to reduce any cross zone costs - this is not HA however. Also there is only private and public subnets.
#There is no service mesh.
#The EKS cluster and ArgoCD will be accessible form the public internet.
#No additional DNZ zone is created.
#Only two general purpose worker nodes are added to the cluster by default.

version: stable
agent_version: latest
steps:
  - name: net
    type: terraform
    workspace: test
    approve: minor
    modules:
      - name: vpc
        source: aws/vpc
        version: stable
        inputs:
          one_nat_gateway_per_az: false
          azs: 2
          intra_subnets: |
            []
          elasticache_subnets: |
            []
          database_subnets: |
            []

  - name: infra
    type: terraform
    workspace: test
    version: stable
    vpc_id: "{{ .ssm.net.vpc.vpc_id }}"
    vpc_subnet_ids: |
      [{{ .ssm.net.vpc.private_subnets }}]
    vpc_security_group_ids: |
      [{{ .ssm.net.vpc.pipeline_security_group }}]
    approve: minor
    modules:
      - name: dns
        source: aws/route53
        version: stable
        inputs:
          vpc_id: "{{ .ssm.net.vpc.vpc_id }}"
          create_public: false
          create_private: false
      - name: eks
        source: aws/eks
        version: stable
        inputs:
          vpc_id: "{{ .ssm.net.vpc.vpc_id }}"
          private_subnets: |
            [{{ .ssm.net.vpc.private_subnets }}]
          public_subnets: |
            [{{ .ssm.net.vpc.public_subnets }}]
          eks_api_access_cidrs: |
            [{{ .ssm.net.vpc.private_subnet_cidrs }}]
          eks_cluster_public: true
          eks_main_min_size: 2
          eks_main_max_size: 6
          eks_spot_max_size: 0
          eks_db_max_size: 0
          cluster_enabled_log_types: |
            []
  - name: helm
    type: terraform
    workspace: test
    version: stable
    vpc_id: "{{ .ssm.net.vpc.vpc_id }}"
    vpc_subnet_ids: |
      [{{ .ssm.net.vpc.private_subnets }}]
    vpc_security_group_ids: |
      [{{ .ssm.net.vpc.pipeline_security_group }}]
    approve: major
    provider:
      inputs:
        eks_cluster_name: "{{ .ssm.infra.eks.cluster_name }}"
    modules:
      - name: crossplane
        source: aws/crossplane
        version: stable
        inputs:
          eks_oidc_provider: "{{ .ssm.infra.eks.oidc_provider }}"
          eks_oidc_provider_arn: "{{ .ssm.infra.eks.oidc_provider_arn }}"
          eks_region: "{{ .ssm.infra.eks.region }}"
          eks_account: "{{ .ssm.infra.eks.account }}"
      - name: argocd
        source: aws/argocd
        version: stable
        inputs:
          hostname: "argocd.{{ .ssm.infra.dns.int_domain }}"
          branch: "{{ .agent.version.helm.argocd }}"
          namespace: "argocd"
          name: "argocd"
          argocd_apps_name: "{{ .config.prefix }}-applications"
          ingress_group_name: "external"
          ingress_scheme: "internet-facing"
  - name: applications
    type: argocd-apps
    workspace: test
    version: stable
    vpc_id: "{{ .ssm.net.vpc.vpc_id }}"
    vpc_subnet_ids: |
      [{{ .ssm.net.vpc.private_subnets }}]
    vpc_security_group_ids: |
      [{{ .ssm.net.vpc.pipeline_security_group }}]
    repo_url: "{{ .ssm.helm.argocd.repo_url }}"
    modules:
      - name: aws-alb
        source: aws-alb
        version: stable
        inputs:
          awsAccount: "{{ .ssm.infra.eks.account }}"
          clusterOIDC: "{{ .ssm.infra.eks.oidc_provider }}"
          aws-load-balancer-controller:
            clusterName: "{{ .ssm.infra.eks.cluster_name }}"
      - name: crossplane-system
        source: crossplane
        version: stable
      - name: external-dns
        source: external-dns
        version: stable
        inputs:
          awsAccount: "{{ .ssm.infra.eks.account }}"
          clusterOIDC: "{{ .ssm.infra.eks.oidc_provider }}"
      - name: aws-storageclass
        source: aws-storageclass
        version: stable

